

## 启动线程的三种方式

1.继承Thread

2: 实现Runnable

 3:Executors.newCachedThrad

## **join()、sleep()、yield()之间的区别**

***join*** : Thread的非静态方法join()让一个线程等待另外一个线程完成才继续执行。如果线程A执行体中调用B线程的join()方法，则A线程将会被阻塞，直到B线程执行完为止，A才能得以继续执行。

**sleep** : 让当前正在执行的线程先暂停一定的时间，并进入阻塞状态。**不释放锁**

***yield*** : 让一个线程执行了yield()方法后，就会进入Runnable(就绪状态)，【不同于sleep()和join（）方法，因为这两个方法是使线程进入阻塞状态】。除此之外，yield()方法还与线程优先级有关，当某个线程调用yield()方法时，就会从运行状态转换到就绪状态后，CPU从就绪状态线程队列中只会选择与该线程优先级相同或者更高优先级的线程去执行。**不释放锁**

## **synchronized**

锁对象不能用String常量 Integer Long等基础数据

类型锁的是对象，不是代码，静态方法锁的是当前类程序

在执行过程中，如果出现异常，默认情况锁会被释放，所以在并发处理的过程中，有异常要多加小心，不然可能会发生不一致的情况，使用try catch捕获处理异常，锁将不会释放。

synchronized获得的锁是可重入的，一个同步方法可以调用另一个同步方法，一个线程已经拥有某个对象的锁，再次申请的时候依然会得到该对象的锁。子类调用父类的同步方法也是能获得锁的。

### **synchronized的底层实现**

JDK早期的 重量级 - OS   需要向操作系统申请锁

后来进行了改进

sync(Object) 

markword 记录这个线程ID ，不申请锁，效率高 (**偏向锁**)

如果线程争用：升级为 **自旋锁 ，**

自旋10次以后，升级为**重量级锁** （系统锁）  

自旋锁占CPU，当不需要向OS申请，系统锁不占CPU，在等待序列中等待执行

执行时间短，线程数比较少用自旋锁，反之用重量级锁

### **Lock与synchronized的区别**

Lock使用的CAS的操作，会一直自旋，直到执行成功，占用CPU

synchronized 不占用CPU,进入等待队列

## **CAS(无锁优化 自旋 乐观锁)**

Compare And Set/Swap   cas(V,Expected,NewValue)  如果输入的值是期望值，将会返回新值，否则重试

cas是CPU原语支持，执行过程中不会被打断

**ABA问题**

执行过程中发生ABA问题，在cas执行前，有线程将值改成B后，又改回为A，跟期待值一致，如果A为基础类型，则无所谓，如果是引用类型，则可能出现问题。

可以通过**加版本号version**解决

像AtomicInteger等以Atomic开头的类，内部是采用的CAS保证线程安全



## Unsafe类

等同于c、c++的指针  直接操作内存  allocateMemory putXX freeMemory pageSize

直接生成类实例 allocateInstance

直接操作类或者实例变量 objectFieldOffset  getInt getObject

CAS相关操作 cas是使用该方法实现的 

weekCompareAndSetObject  Int Long (11.0版本)  

1.8版本是compareAndSwapObject Int Long



## **内核态和用户态**

Linux内核占用一部分内存，用户应用程序也占用一部分内存，Linux内核可以访问所有内存,用户应用程序只能访问用户应用程序的内存，不能访问Linux内核占用的内存

**内核态**： cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

**用户态**: 只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。



## **volatile**

所有的变量都存储在主内存中，每个线程还有自己的工作内存，线程的工作内存中保存该线程使用到的变量，要从主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在自己的工作内存中，不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存中完成。

volatile 强制所有线程都去堆内存中读取变量值，**保证线程可见性** ，以免线程之间数据发生改变，其他线程不能及时感知。

volatile引用类型（包括数组）只能保证引用本身的可见性，不能保证保证内部字段的可见性。

MESI 缓存一致性协议

**禁止指令重排序**（CPU） DCL单例 （双重检查Double Check Lock）
synchronized 可以保证可见性和原子性，volatile只能保证可见性。

## **LongAdder**

LongAdder采用分段锁，在并发数很多的时候效率更高。

## **ReentrantLock**

使用lock()和unlock()来加锁和解锁，unlock()要写在finally中，以免程序发生异常，没有释放锁。

使用reentrantLock进行尝试锁定tryLock，当无法锁定，或者在指定时间内无法锁定，线程可以决定是否继续等待

使用lockInterruptibly()，可以对interrupt()方法做出响应，进行解锁ReentrantLock构造函数参数传true，则会创建公平锁，锁是先到先得，默认是非公平锁

## **CountDownLatch**

CountDownLatch初始化时设置线程数，每执行完一个线程调用countDown()方法，表示线程数减一，该方法是线程安全的，不需要sync，执行await方法会让当前线程阻塞，直到所有线程执行完。

```java
CountDownLatch latch = new CountDownLatch(threads.length);  
latch.countDown();
latch.await();
```

## **CyclicBarrier**

当需要所有线程达到一定的数量，操作才能放行

```java
CyclicBarrier barrier = new CyclicBarrier(20, () -> System.out.println("满人"));
barrier.await();
```

## **Phaser**

阶段器，必须所有线程完成才能进入下一个阶段

```java
MarriagePhaser phaser = new MarriagePhaser();  //MarriagePhaser是Phaser的子类，需要实现onAdvance方法
phaser.bulkRegister(5);     //注册线程数量
phaser.arriveAndAwaitAdvance();  //完成了当前阶段，并等待其他线程完成后进入下一个阶段
phaser.arriveAndDeregister();    //完成了当前阶段，不再进入下一个阶段
phaser.register();         //加入新的线程到当前阶段
```

## **ReadWriteLock**

锁和排它锁，当没有写操作时，所有线程都可以同时读数据，当有写操作时，就会加排他锁，只有有一个线程操作。

```java
ReadWriteLock readWriteLock = new RentrantReadWriteLock();
Lock readLock =readWriteLock.readLock();
Lock writeLock = readWriteLock.writeLock();
```

## **Semaphore**

Semaphore初始化时设置允许并发执行的线程数，可用于限流

```java
Semaphore s = new Semaphore(1);s.acquire();       //在线程开始执行时，申请线程执行许可，获取到许可才能执行，否则等待
s.release()       //线程结束时，释放执行许可权
```

## **Exchanger**

只能两个线程之间交换数据

```
Exchanger<String> exchanger = new Exchanger<>();
s = exchanger.exchange(s);  //执行后当前线程切换成阻塞状态，直到另一线程执行该方法，交换数据后继续执行
```

## **LockSupport**

```
LockSupport.park();     //让当前线程进入阻塞状态
LockSupport.unpark(t);   //让t线程解除阻塞unpark方法是可以在park方法之前使用的，如果执行unpark方法，再执行park方法，线程不会进入阻塞状态，会继续运行
```

## **VarHandle**

可以获取对象的引用，对对象进行操作，JDK1.9新增的类

1.普通属性原子操作

2.比反射快，直接操纵二进制码

## **ThreadLocal 线程局部变量**

当往ThreadLocal对象中获取值时，只能获取当前线程设置的值，无法获取到其它线程设置的值，

因为ThreadLocal是将值保存到当前线程的map对象中（Thread的ThreadLocalMap），每个线程会有一个map对象，每个线程的值是相互隔离的，map的key为ThreadLocal对象，通过ThreadLocal对象就能获取到对应的值。

ThreadLocal是使用空间换时间，synchronized是使用时间换空间

**用途 ：** 声明式事务 ，保证同一个Connection

ThreadLocal中的Entry是使用弱引用

## 强软弱虚种引用

**Java引用类型有 强软弱虚种引用**

**强引用**就是普通引用

**软引用**（SoftRefennce）：内存够时 ，gc不会回收，只有当内存不够时，才会自动回收，可用于缓存数据   

软引用是用来描述一些还有用但并非必须的对象。   

对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围进行第二次回收。   如果这次回收还没有足够的内存，才会抛出内存溢出异常。

**弱引用**（WeakReference）：每次遭到gc就会回收

**虚引用**（PhantomReference）：每次gc后，虚引用会回收，回收后的引用会放到队列Quene里。一般用于回收堆外内存，当对象被回收时，通过Quene可以检测到，然后清理堆外内存。   

一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获取一个对象的实例。   

为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。   

虚引用和弱引用对关联对象的回收都不会产生影响，如果只有虚引用活着弱引用关联着对象，  那么这个对象就会被回收。它们的不同之处在于弱引用的get方法，虚引用的get方法始终返回null,   弱引用可以使ReferenceQueue,虚引用必须配合ReferenceQueue使用。     

jdk中直接内存的回收就用到虚引用，由于jvm自动内存管理的范围是堆内存，   

而直接内存是在堆内存之外（其实是内存映射文件，自行去理解虚拟内存空间的相关概念），   

所以直接内存的分配和回收都是有Unsafe类去操作，java在申请一块直接内存之后，   

会在堆内存分配一个对象保存这个堆外内存的引用，  

这个对象被垃圾收集器管理，一旦这个对象被回收，   

相应的用户线程会收到通知并对直接内存进行清理工作。   

事实上，虚引用有一个很重要的用途就是用来做堆外内存的释放，   

DirectByteBuffer就是通过虚引用来实现堆外内存的释放的。

## **同步容器类**

在物理结构只有连续存储的数组和非连续存储的链表。Quene是后期加的，专门用于多线程。ConcurrentLinkedQueue内部是CAS实现的。 

1：Vector Hashtable ：早期使用synchronized实现

2：ArrayList HashSet ：未考虑多线程安全（未实现同步）

3：HashSet vs Hashtable StringBuilder vs StringBuffer

4：Collections.synchronized***工厂方法使用的也是synchronized
使用早期的同步容器以及Collections.synchronized***方法的不足之处，请阅读：http://blog.csdn.net/itm_hadf/article/details/7506529
使用新的并发容器http://xuganggogo.iteye.com/blog/321630



Vector和Hashtable自带锁,线程安全，很少使用。后来出现SynchronizedHashMap，即Collections.synchronizedMap

ConcurrentHashMap和SynchronizedHashMap都是线程安全的，ConcurrentHashMap写入时效率低，获取数据效率高，SynchronizedHashMap相反，写入效率高，获取数据效率低。

ConcurrentSkipListMap是线程安全并且排序，跳表。

TreeMap是排序的，查找效率高，是红黑树实现的

CopyOnWriteArrayList用于写操作少，读操作多的情况，读不加锁，写时加锁，复制数组ConcurrentLinkedQueue  FIFO先进先出，线程安全，使用链表结构

LinkedBlockingQueue 内部是链表实现，最大长度为Integer的最大值，put()满了就会等待 take()没有数据会等待，这两个方法是阻塞的

ArrayBlockingQueue 有界，内部是数组实现DelayQueue 指定延迟一定时间后获取，内部会按照延迟时间排序，延迟时间短的先获取PriorityQueue 内部设置了排序，最小的在最上面，内部是数结构

SynchronousQueue 与Exchanger类似，容量为0，用于线程之间交换数据，使用take和put方法获取和添加数据，这两个方法是阻塞的

LinkedTransferQueue 也是用于线程间传递数据，是有长度的，添加了transfer方法，使用transfer添加数据，会一直阻塞，直到数据被取出
Queue与List的区别在于，Queue添加了对线程友好的API，添加了offer peek poll方法，同时BlockingQueue还添加了put和take的阻塞方法

![容器](.\images\容器.jpg)

## Callable

Callable与Runnable类似，只是会有返回值。一般与线程池结合使用

## Future

 存储线程将来执行的，才能产生的结果

```java
ExecutorService service = Executors.newCachedThreadPool();
Future<String> future = service.submit(c); //异步，返回Future对象
System.out.println(future.get()); //get()方法为阻塞的，直到线程执行完成并返回数据 
```

## FutureTask 

FutureTask -> Future + Runnable

```java
FutureTask<Integer> task = new FutureTask<>(()->{  
    TimeUnit.MILLISECONDS.sleep(500);  return 1000;
}); 
new Thread(task).start();
```

## CompletableFuture 

CompletableFuture 对线程任务进行管理，对多个Future结果组合处理

```java
CompletableFuture<Double> futureTM = CompletableFuture.supplyAsync(()->priceOfTM());
CompletableFuture<Double> futureTB = CompletableFuture.supplyAsync(()->priceOfTB());
CompletableFuture<Double> futureJD = CompletableFuture.supplyAsync(()->priceOfJD());
CompletableFuture.allOf(futureTM, futureTB, futureJD).join(); //3个任务并发执行，并等3个任务都执行完才解除阻塞执行下一步
CompletableFuture.supplyAsync(()->priceOfTM())    
.thenApply(String::valueOf)    
.thenApply(str-> "price " + str)    
.thenAccept(System.out::println);
```

## **线程池**

线程池有ThreadPoolExecutor和ForkJoinPool两种

ThreadPoolExecutor是普通线程池

ForkJoinPool   会分解汇总的任务，   用很少的线程可以执行很多的任务（子任务），TPE做不到先执行子任务  CPU密集型

### ThreadPoolExecutor

```java
ThreadPoolExecutor tpe = new ThreadPoolExecutor(2, 4,    
  60, TimeUnit.SECONDS,    
new ArrayBlockingQueue<Runnable>(4),    
Executors.defaultThreadFactory(),    
new ThreadPoolExecutor.CallerRunsPolicy());
```

第一个参数 corePoolSize 核心线程数，即使线程空闲，也保持在池中的线程数量，除非设置了allowCoreThreadTimeOut

第二个参数 maximumPoolSize 线程池中允许的最大线程数

第三个参数 keepAliveTime 当线程数大于心线程数时，线程空闲时间大于keepAliveTime 时将会被释放

第四个参数 unit 设置keepAliveTime 的单位

第五个参数 workQueue 类型为BlockingQueue<Runnable>，用来存放等待执行的任务

第六个参数 threadFactory 创建线程的工厂类

第七个参数 handler ,线程池对拒绝任务的处理策略。当线程数和任务队列满了，新的任务无法得到执行时采用的处理策略，可以用自定义的策略，也可以用 jdk提供了4种默认的处理策略：  

1.  AbortPolicy 放弃执行，并抛出RejectedExecutionException异常,默认的
2.  DiscardPolicy 放弃执行，什么操作也不做   
3. DiscardOldestPolicy 丢弃任务队列中等待时间最长的任务，然后加入新任务  
4.  CallerRunsPolicy 让调用线程执行任务

### ForkJoinPool

ForkJoinPool执行的任务需要实现ForkJoinTask类，ForkJoinTask有两个子类，RecursiveAction和RecursiveTask，RecursiveAction不带返回值，RecursiveTask带返回值。

采用RecursiveAction实现

```java
static class AddTask extends RecursiveAction {

		int start, end;

		AddTask(int s, int e) {
			start = s;
			end = e;
		}

		@Override
		protected void compute() {

			if(end-start <= MAX_NUM) {
				long sum = 0L;
				for(int i=start; i<end; i++) sum += nums[i];
				System.out.println("from:" + start + " to:" + end + " = " + sum);
			} else {
				int middle = start + (end-start)/2;

				AddTask subTask1 = new AddTask(start, middle);
				AddTask subTask2 = new AddTask(middle, end);
				subTask1.fork();
				subTask2.fork();
			}
		}
	}
	
	
		ForkJoinPool fjp = new ForkJoinPool();
		AddTask task = new AddTask(0, nums.length);
		fjp.execute(task);
```

采用RecursiveTask实现

```java
static class AddTaskRet extends RecursiveTask<Long> {
   
   private static final long serialVersionUID = 1L;
   int start, end;
   
   AddTaskRet(int s, int e) {
      start = s;
      end = e;
   }

   @Override
   protected Long compute() {
      
      if(end-start <= MAX_NUM) {
         long sum = 0L;
         for(int i=start; i<end; i++) sum += nums[i];
         return sum;
      } 
      
      int middle = start + (end-start)/2;
      
      AddTaskRet subTask1 = new AddTaskRet(start, middle);
      AddTaskRet subTask2 = new AddTaskRet(middle, end);
      subTask1.fork();
      subTask2.fork();
      
      return subTask1.join() + subTask2.join();
   }
}

		ForkJoinPool fjp = new ForkJoinPool();
		AddTaskRet task = new AddTaskRet(0, nums.length);
		fjp.execute(task);
		long result = task.join();
		System.out.println(result);
```

### Executors

线程池工厂，不建议使用，建议自己创建线程池

1. SingleThreadExecutor 单线程的线程池

   当一个任务提交时，首先会创建一个核心线程来执行任务，如果超过核心线程的数量，将会放入队列中，**因为`LinkedBlockingQueue`是长度为`Integer.MAX_VALUE`的队列，可以认为是无界队列，因此往队列中可以插入无限多的任务，在资源有限的时候容易引起`OOM`异常**，同时因为无界队列，`maximumPoolSize`和`keepAliveTime`参数将无效，压根就不会创建非核心线程

   ```java
   ExecutorService service = Executors.newSingleThreadExecutor();
   
   public static ExecutorService newSingleThreadExecutor() {
       return new FinalizableDelegatedExecutorService
           (new ThreadPoolExecutor(1, 1,
                                   0L, TimeUnit.MILLISECONDS,
                                   new LinkedBlockingQueue<Runnable>()));
   }
   ```

   > 为什么要有单线程的线程池？
   >
   > 1. 线程池是有任务队列的
   > 2. 线程池有完整的生命周期管理

2. CachedThreadPool   最大线程数为Integer.MAX_VALUE，每次线程请求都会创建一个线程，当线程数过大时，会占用过多的CPU资源

   当一个任务提交时，`corePoolSize`为0不创建核心线程，`SynchronousQueue`是一个不存储元素的队列，可以理解为队里永远是满的，因此最终会创建非核心线程来执行任务。对于非核心线程空闲60s时将被回收。**因为`Integer.MAX_VALUE`非常大，可以认为是可以无限创建线程的，在资源有限的情况下容易引起OOM异常**

```java
ExecutorService service = Executors.newCachedThreadPool();

public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```

3. FixedThreadPool  创建时设置固定大小的线程数

   workQueue => LinkedBlockingQueue 它和`SingleThreadExecutor`类似，唯一的区别就是核心线程数不同，并且由于**使用的是`LinkedBlockingQueue`，在资源有限的时候容易引起`OOM`异常**

```java
ExecutorService service = Executors.newFixedThreadPool(cpuCoreNum);

public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>());
}
```

  线程数大小要根据运行环境选择合适的值

4. ScheduledThreadPool 定时任务线程池

   ```java
   ScheduledExecutorService service = Executors.newScheduledThreadPool(4);
   service.scheduleAtFixedRate(()->{
      try {
         TimeUnit.MILLISECONDS.sleep(new Random().nextInt(1000));
      } catch (InterruptedException e) {
         e.printStackTrace();
      }
      System.out.println(Thread.currentThread().getName());
   }, 0, 500, TimeUnit.MILLISECONDS);
   
   public ScheduledThreadPoolExecutor(int corePoolSize) {
           super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
                 new DelayedWorkQueue());
    }
   ```

   > 复杂的定时任务可采用quartz cron框架实现

5. WorkStealingPool  每个线程会单独维护一个任务队列，当线程空闲时，会从其他线程的任务队列中去任务执行，是ForkJoinPool

```java
ExecutorService service = Executors.newWorkStealingPool();

public static ExecutorService newWorkStealingPool() {
        return new ForkJoinPool
            (Runtime.getRuntime().availableProcessors(),
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
```

### 如何定义线程池参数

- **CPU密集型** => 线程池的大小推荐为`CPU`数量 + 1，`CPU`数量可以根据`Runtime.availableProcessors`方法获取

- **IO密集型** => `CPU`数量 * `CPU`利用率 * (1 + 线程等待时间/线程CPU时间)

- **混合型** => 将任务分为`CPU`密集型和`IO`密集型，然后分别使用不同的线程池去处理，从而使每个线程池可以根据各自的工作负载来调整

- **阻塞队列** => 推荐使用有界队列，有界队列有助于避免资源耗尽的情况发生

- **拒绝策略** => 默认采用的是`AbortPolicy`拒绝策略，直接在程序中抛出`RejectedExecutionException`异常【因为是运行时异常，不强制`catch`】，这种处理方式不够优雅。处理拒绝策略有以下几种比较推荐：

- - 在程序中捕获`RejectedExecutionException`异常，在捕获异常中对任务进行处理。针对默认拒绝策略
  - 使用`CallerRunsPolicy`拒绝策略，该策略会将任务交给调用execute的线程执行【一般为主线程】，此时主线程将在一段时间内不能提交任何任务，从而使工作线程处理正在执行的任务。此时提交的线程将被保存在`TCP`队列中，TCP队列满将会影响客户端，这是一种平缓的性能降低
  - 自定义拒绝策略，只需要实现`RejectedExecutionHandler`接口即可
  - 如果任务不是特别重要，使用`DiscardPolicy`和`DiscardOldestPolicy`拒绝策略将任务丢弃也是可以的

如果使用Executors的静态方法创建`ThreadPoolExecutor`对象，可以通过使用`Semaphore`对任务的执行进行限流也可以避免出现`OOM`异常

### parallelStream

使用parallel stream api 效率比单线程更高，内部是ForkJoinPool实现的

```java
List<Integer> nums = new ArrayList<>();
for(int i=0; i<10000; i++) 
    nums.add(1000000 + r.nextInt(1000000));
//使用parallel stream api
nums.parallelStream().forEach(T13_ParallelStreamAPI::isPrime);
```

## 并发和并行

Concurrent vs parallel

并发是指任务提交，并行指任务执行

并行是并发的子集，并发是多个任务同时执行，并行是多个CPU同时处理



读AQS unlock源码 和 弱引用源码






































